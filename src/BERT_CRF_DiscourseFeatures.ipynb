{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import ktrain \n",
    "from ktrain import text\n",
    "import torch \n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "##set seed\n",
    "import random \n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAwareModel(): \n",
    "    \n",
    "    def __init__ (self): \n",
    "        self.set_seed(1,1)\n",
    "        \n",
    "    def set_seed(self,num, n_gpu):\n",
    "        random.seed(num)\n",
    "        np.random.seed(num)\n",
    "        tf.random.set_seed(num)\n",
    "        try: \n",
    "            torch.manual_seed(num)\n",
    "        except NameError: \n",
    "            pass\n",
    "        if n_gpu > 0:\n",
    "                torch.cuda.manual_seed_all(num)\n",
    "                \n",
    "                \n",
    "    def make_dir(self, outpath):\n",
    "        path = outpath + '/Folds'\n",
    "        path2 = outpath + '/BERTprobs'\n",
    "        path3 = outpath + '/FeatureSelect'\n",
    "        path4 = outpath + '/BERTpredictors'\n",
    "\n",
    "        for i in [path, path2, path3, path4]:\n",
    "            try:\n",
    "                os.mkdir(i)\n",
    "            except OSError:\n",
    "                print (\"Creation of the directory %s failed\" % i)\n",
    "            else:\n",
    "                print (\"Successfully created the directory %s \" % i)\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "    def save_obj(self, obj, name):\n",
    "        with open(name + '.pkl', 'wb') as f:\n",
    "            pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def create_one_fold(self, d, dev, test, outpath, suffix):  \n",
    "        \n",
    "        dt = defaultdict(list)\n",
    "        train= []\n",
    "        dev2 = []\n",
    "        test2 = []\n",
    "        \n",
    "        for num, i in enumerate(self.all_sets): \n",
    "#             print(len(i))\n",
    "            if num != dev and num!= test: \n",
    "                for conv in i: \n",
    "#                     print(conv)\n",
    "                    [train.append(j) for j in d[conv]]\n",
    "                    \n",
    "\n",
    "        for conv in self.all_sets[dev]: \n",
    "            [dev2.append(j) for j in d[conv]]\n",
    "\n",
    "        for conv in self.all_sets[test]: \n",
    "            [test2.append(j) for j in d[conv]]\n",
    "        \n",
    "        \n",
    "        dt['train'] = train\n",
    "        dt['dev'] = dev2\n",
    "        dt['test'] = test2\n",
    "\n",
    "#         print(dt['test'])\n",
    "\n",
    "        outpath2 = outpath + 'Folds/' + suffix\n",
    "        self.save_obj(dt, outpath2)\n",
    "        return dt\n",
    "\n",
    "    def create_fold_dict(self, data, outpath): \n",
    "        ##get all thread ids\n",
    "        lst = list(set(list(data.thread_id)))\n",
    "        \n",
    "        self.all_sets = []\n",
    "        kf = KFold(n_splits=10, random_state = 10)\n",
    "        kf.get_n_splits(lst)\n",
    "        for train_index, test_index in kf.split(lst):\n",
    "            s = []\n",
    "            for i in test_index: \n",
    "                s.append(lst[i])\n",
    "            self.all_sets.append(s)\n",
    "            \n",
    "        print(len(self.all_sets))\n",
    "\n",
    "        d = {}\n",
    "        for i in lst: \n",
    "            df = data[data.thread_id == i]\n",
    "#             print(len(df))\n",
    "            d[i] = list(set(df.post_id))\n",
    "            \n",
    "#         print(d)\n",
    "        \n",
    "        self.folddicts= []\n",
    "        \n",
    "        for test, dev, suffix in zip([0,1,2,3,4,5,6,7,8,9], [1,2,3,4,5,6,7,8,9,0], ['fold1', 'fold2','fold3', 'fold4', 'fold5', 'fold6', 'fold7','fold8', 'fold9', 'fold10']): \n",
    "            x = self.create_one_fold(d, dev, test, outpath, suffix)\n",
    "            self.folddicts.append(x)\n",
    "            \n",
    "    \n",
    "    def reformat_for_bert (self, data,label, folddict): ##need commenttxt and label \n",
    "        x = folddict['dev']\n",
    "        y = folddict['train']\n",
    "        z = folddict['test']\n",
    "\n",
    "        data[label] = pd.Categorical(data[label])\n",
    "        data[label] = data[label].cat.codes\n",
    "\n",
    "        dev_df = data[data.post_id.isin(x)]\n",
    "        train_df = data[data.post_id.isin(y)]\n",
    "        test_df = data[data.post_id.isin(z)]\n",
    "\n",
    "        y_dev = dev_df[label]\n",
    "        y_train = train_df[label]\n",
    "        y_test = test_df[label]\n",
    "\n",
    "        X_dev = dev_df.comment_text\n",
    "        X_train = train_df.comment_text\n",
    "        X_test = test_df.comment_text\n",
    "\n",
    "        print('The length of the test data is: ' + str(len(X_test)))\n",
    "        print('The lenght of the train data is: ' + str(len(X_train)))\n",
    "        print('The lenght of the dev data is: ' + str(len(X_dev)))\n",
    "\n",
    "        return X_dev, y_dev, X_train, y_train, X_test, y_test\n",
    "    \n",
    "    \n",
    "\n",
    "    def run_BERT_model(self, data, fold, sufix, label, t, base_out_path, epochs =3): \n",
    "\n",
    "        X_dev, y_dev, X_train, y_train, X_test, y_test = self.reformat_for_bert(data, label, fold)\n",
    "        X_train2 = [str(i) for i in X_train]\n",
    "        X_test2 = [str(i) for i in X_test]\n",
    "        X_dev2 = [str(i) for i in X_dev]\n",
    "\n",
    "        y_test2 = [str(i) for i in y_test]\n",
    "        y_train2 = [str(i) for i in y_train]\n",
    "        y_dev2 = [str(i) for i in y_dev]\n",
    "\n",
    "        trn = t.preprocess_train (X_train2, y_train2)\n",
    "        val = t.preprocess_test(X_dev2, y_dev2)\n",
    "        test = t.preprocess_test(X_test2, y_test2)\n",
    "\n",
    "        model = t.get_classifier()\n",
    "        learner = ktrain.get_learner(model, train_data = trn, val_data =val, batch_size = 32)\n",
    "        hist1 = learner.fit_onecycle(5e-5, epochs)\n",
    "\n",
    "        predictor1 = ktrain.get_predictor(learner.model, preproc=t)\n",
    "\n",
    "        hist2 = learner.fit_onecycle(5e-5, 1)\n",
    "\n",
    "        predictor2 = ktrain.get_predictor(learner.model, preproc=t)\n",
    "\n",
    "\n",
    "        v1 = hist1.history['val_accuracy'] \n",
    "        v2 = hist2.history['val_accuracy']\n",
    "\n",
    "        if v1 >= v2: \n",
    "            chosen = 3\n",
    "            self.save_obj(chosen, (base_out_path + '/BERTpredictors/chosen_epochs_' + sufix))\n",
    "            predictor1.save(base_out_path + '/BERTpredictors/predictor1_' + sufix )\n",
    "\n",
    "#             res_test = predictor1.predict(X_test2)\n",
    "            res = predictor1.predict(X_test2, return_proba = True)\n",
    "            res_train = predictor1.predict(X_train2, return_proba = True)\n",
    "            res_dev = predictor1.predict(X_dev2, return_proba = True)\n",
    "        else: \n",
    "            chosen = 4\n",
    "            self.save_obj(chosen, (base_out_path + '/BERTpredictors/chosen_epochs_' + sufix))\n",
    "            predictor2.save(base_out_path + '/BERTpredictors/predictor2_' + sufix )\n",
    "            \n",
    "#             res_test = predictor2.predict(X_test2)\n",
    "            res = predictor2.predict(X_test2, return_proba = True)\n",
    "            res_train = predictor2.predict(X_train2, return_proba = True)\n",
    "            res_dev = predictor2.predict(X_dev2, return_proba = True)\n",
    "         \n",
    "        \n",
    "#         f1_out = f1_score (y_true = y_test2, y_pred = res_test)\n",
    "#         recall_out = recall_score(y_true =  y_test2, y_pred = res_test)\n",
    "#         prec_out = precision_score (y_true =  y_test2, y_pred = res_test)\n",
    " \n",
    "        outpath = base_out_path + 'BERTprobs/probs_' + sufix + '.npy'\n",
    "        np.save(outpath, res, allow_pickle=False)\n",
    "        outpath2 = base_out_path + 'BERTprobs/probs_train_' + sufix + '.npy'\n",
    "        np.save(outpath2, res_train, allow_pickle=False)\n",
    "        outpath3 = base_out_path + 'BERTprobs/probs_dev_' + sufix + '.npy'\n",
    "        np.save(outpath3, res_dev, allow_pickle=False)\n",
    "        \n",
    "#         return f1_out, recall_out, prec_out\n",
    "    \n",
    "    def run_BERT(self, data, outpath): \n",
    "        maxlen=128\n",
    "        MODELNAME='distilbert-base-uncased'\n",
    "        t = text.Transformer(MODELNAME, maxlen=maxlen, classes=[0,1])\n",
    "        \n",
    "        out = defaultdict(dict)\n",
    "        \n",
    "        print(len(self.folddicts[0]['test']))\n",
    "        \n",
    "        for a,b in zip(self.folddicts, ['fold1', 'fold2','fold3', 'fold4', 'fold5', 'fold6', 'fold7','fold8', 'fold9', 'fold10']):\n",
    "            self.run_BERT_model (data, a, b, 'label', t, outpath)\n",
    "#             out['F1'].append(f1_out)\n",
    "#             out['recall'].append(recall_out)\n",
    "#             out['precision'].append(prec_out)\n",
    "  \n",
    "        print('BERT is done')\n",
    "        \n",
    "        ##print average outcome \n",
    "#         print('The mean F1 score is: ')\n",
    "#         print(np.mean(out['F1']))\n",
    "\n",
    "    def calculate_BERT_metrics(self, data, outpath): \n",
    "        out = defaultdict(list)\n",
    "        \n",
    "        for a,b in zip(self.folddicts, ['fold1', 'fold2','fold3', 'fold4', 'fold5', 'fold6', 'fold7','fold8', 'fold9', 'fold10']):\n",
    "            y_true = self.collect_y_true(a, data)\n",
    "            ##collect probs\n",
    "            path = outpath + '/BERTprobs/probs_' + b + '.npy'\n",
    "            p = np.load (path)\n",
    "            \n",
    "            y_pred = self.reformat_probas(p)\n",
    "            \n",
    "#             print(len(y_true))\n",
    "#             print(len(y_pred))\n",
    "            \n",
    "            f = f1_score(y_pred = y_pred, y_true = y_true)\n",
    "            p = precision_score(y_pred = y_pred, y_true = y_true)\n",
    "            r = recall_score(y_pred = y_pred, y_true=y_true)\n",
    "\n",
    "            out['F1'].append(f)\n",
    "            out['Recall'].append(r)\n",
    "            out['Precision'].append(p)\n",
    "            \n",
    "        ##print\n",
    "        print('The F1 score for BERT is: ')\n",
    "        avg = np.mean(out['F1'])\n",
    "        print(avg)\n",
    "        \n",
    "        ##save \n",
    "        self.save_obj(out, outpath + 'BERTresults')\n",
    "        \n",
    "    \n",
    "    def collect_y_true(self, folddict, data): \n",
    "        z = folddict['test']\n",
    "#         print(len(z))\n",
    "        test_df = data[data.post_id.isin(z)]\n",
    "\n",
    "        y_test = test_df.label\n",
    "\n",
    "        return y_test\n",
    "    \n",
    "    def reformat_probas(self, probas): \n",
    "        x = probas[0]\n",
    "        df = pd.DataFrame(x)\n",
    "        y_pred= []\n",
    "        for a,b in zip(df[0], df[1]): \n",
    "            if a > b: \n",
    "                y_pred.append(0)\n",
    "            else: \n",
    "                y_pred.append(1)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "        \n",
    "    def obtain_probas_nw (self, data, folddict, foldname, basepath, rightid = 'post_id'):\n",
    "        ###load the right probas\n",
    "        probas_dev = np.load(basepath + 'probs_dev_' + foldname + '.npy')\n",
    "        probas_test = np.load(basepath + 'probs_' + foldname + '.npy')\n",
    "        probas_train= np.load(basepath + 'probs_train_' + foldname + '.npy')\n",
    "\n",
    "        ##reformat\n",
    "        x = folddict['dev']\n",
    "        y = folddict['train']\n",
    "    #     nw_x = list(set(x).union(set(y)))\n",
    "        z = folddict['test']\n",
    "#         print(len(z))\n",
    "        ##first get post ids\n",
    "\n",
    "        dev_df0 =  data[data[rightid].isin(x)]\n",
    "        train_df0 = data[data[rightid].isin(y)]\n",
    "        test_df0 = data[data[rightid].isin(z)]\n",
    "\n",
    "        train_df_nw = pd.concat([train_df0, dev_df0],axis=0)\n",
    "\n",
    "        dev_posts =list(dev_df0.post_id)\n",
    "        train_posts= list(train_df0.post_id)\n",
    "        test_posts = list(test_df0.post_id)\n",
    "\n",
    "#         print(len(dev_posts))\n",
    "#         print(len(probas_dev))\n",
    "\n",
    "        trainlbls = list(train_df_nw.label)\n",
    "        testlbls = list(test_df0.label)\n",
    "\n",
    "        df_test = pd.DataFrame(probas_test[0])\n",
    "        df_train = pd.DataFrame(probas_train[0])\n",
    "        df_dev = pd.DataFrame(probas_dev[0])\n",
    "\n",
    "        df_train_nw= pd.concat([df_train, df_dev], axis =0)\n",
    "\n",
    "        df_test.columns = ['Predictions0', 'Predictions1']\n",
    "        df_train_nw.columns = ['Predictions0', 'Predictions1']\n",
    "\n",
    "\n",
    "        train_q = list(train_df0.thread_id)\n",
    "        test_q = list(test_df0.thread_id)\n",
    "\n",
    "        df_train_nw = df_train_nw.reset_index(drop= True)\n",
    "\n",
    "\n",
    "        return df_train_nw, df_test, trainlbls, testlbls, train_q, test_q\n",
    "        \n",
    "    \n",
    "    def get_thread_startpoints (self, lst1): ##list is a list of the question ids \n",
    "        lst2= []\n",
    "        current_q = 0\n",
    "        for num,i in enumerate(lst1): \n",
    "            if num == 0: \n",
    "                lst2.append(0)\n",
    "                current_q = i\n",
    "    #             pass\n",
    "            elif current_q == i: ##same question \n",
    "                lst2.append(0)\n",
    "            else: ##different question\n",
    "                lst2.append(1)\n",
    "                current_q = i\n",
    "        return lst2\n",
    "\n",
    "    def reformat_for_crf(self, train_df, startp): \n",
    "        #first turn it into one long list of dictionaries \n",
    "        nwcolnames= [str(i) for i in train_df.columns]\n",
    "        train_df.columns = nwcolnames\n",
    "    #     print(train_df.head())\n",
    "\n",
    "        d= train_df.to_dict('records')\n",
    "\n",
    "        out = []\n",
    "        temp= []\n",
    "        for a,b in zip(d, startp): \n",
    "            if b == 1: \n",
    "                out.append(temp)\n",
    "                temp = []\n",
    "                temp.append(a)\n",
    "            else: \n",
    "                temp.append(a)\n",
    "        out.append(temp)\n",
    "        return out\n",
    "\n",
    "    def transform_sent_vecs_into_df(self, sent_vecs): \n",
    "        df = pd.DataFrame(sent_vecs[0])\n",
    "    #     df2 = df.transpose()\n",
    "        for i in sent_vecs[1:]: \n",
    "            y = pd.Series(i)\n",
    "    #         y2 = y.transpose()\n",
    "            df = pd.concat([df, y], axis=1)\n",
    "        df3 = df.transpose()\n",
    "        return df3\n",
    "\n",
    "    def reformat_labels(self, data, startp): \n",
    "        out = []\n",
    "        temp= []\n",
    "        for a,b in zip(data.label, startp): \n",
    "            if b == 1: \n",
    "                out.append(temp)\n",
    "                temp = []\n",
    "                temp.append(str(a))\n",
    "            else: \n",
    "                temp.append(str(a))\n",
    "        out.append(temp)\n",
    "        return out\n",
    "\n",
    "    def reformat_labels_blend(self, lbls, startp): \n",
    "        out = []\n",
    "        temp= []\n",
    "        for a,b in zip(lbls, startp): \n",
    "            if b == 1: \n",
    "                out.append(temp)\n",
    "                temp = []\n",
    "                temp.append(str(a))\n",
    "            else: \n",
    "                temp.append(str(a))\n",
    "        out.append(temp)\n",
    "        return out\n",
    "    \n",
    "    def obtain_other_features(self, data, folddict,rightid = 'post_id'):\n",
    "    \n",
    "         ##reformat\n",
    "        x = folddict['dev']\n",
    "        y = folddict['train']\n",
    "        z = folddict['test']\n",
    "\n",
    "        ##first get post ids\n",
    "\n",
    "        dev_df0 =  data[data[rightid].isin(x)]\n",
    "        train_df0 = data[data[rightid].isin(y)]\n",
    "        test_df0 = data[data[rightid].isin(z)]\n",
    "\n",
    "        train_df = pd.concat([train_df0, dev_df0], axis =0)\n",
    "        train_df = train_df.fillna(999)\n",
    "        test_df = test_df0.fillna(999)\n",
    "\n",
    "        train_df = train_df.reset_index(drop = True)\n",
    "        test_df = test_df.reset_index(drop = True)\n",
    "\n",
    "        return train_df, test_df\n",
    "    \n",
    "    def run_BlendedBERTCRF(self, data, basepath_probas): \n",
    "        out = defaultdict(list)\n",
    "        params_space = {\n",
    "                'c1': scipy.stats.expon(scale=0.5),\n",
    "                'c2': scipy.stats.expon(scale=0.05),\n",
    "            }\n",
    "\n",
    "        f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                            average='weighted',  labels=[0,1])\n",
    "\n",
    "        for d, w in zip(self.folddicts, ['fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9', 'fold10']):\n",
    "\n",
    "            crf = sklearn_crfsuite.CRF(\n",
    "                algorithm='lbfgs',\n",
    "                max_iterations=100,\n",
    "                all_possible_transitions=True\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            rs = RandomizedSearchCV(crf, params_space,\n",
    "                                    cv=9,\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=-1,\n",
    "                                    n_iter=50,\n",
    "                                    scoring=f1_scorer)\n",
    "\n",
    "#             print(d.keys())\n",
    "            train_df, test_df, trainlbls, testlbls, train_q, test_q = self.obtain_probas_nw(data, d, w, basepath_probas)\n",
    "    #         print(train_df.head())\n",
    "\n",
    "            X_train = train_df\n",
    "            y_train = trainlbls\n",
    "\n",
    "            X_test = test_df\n",
    "            y_test = testlbls\n",
    "\n",
    "            #get thread start points\n",
    "    #         lst = train_df.question_post_id\n",
    "            startp = self.get_thread_startpoints(train_q)\n",
    "            y_train = self.reformat_labels_blend(trainlbls, startp)\n",
    "\n",
    "            #reformat X_train\n",
    "            X_train_nw = self.reformat_for_crf(X_train, startp)\n",
    "\n",
    "            startp = self.get_thread_startpoints(test_q)\n",
    "            y_test = self.reformat_labels_blend(testlbls, startp)\n",
    "\n",
    "            X_test_nw = self.reformat_for_crf(X_test, startp)\n",
    "    \n",
    "            rs.fit(X_train_nw, y_train)\n",
    "\n",
    "#             print(\"\\nBest Score = \" + str(rs.best_score_) + ' for the parameters ' + str(rs.best_params_))\n",
    "    #     \n",
    "            y_pred = rs.predict (X_test_nw)\n",
    "\n",
    "            y_test_exp = [int(i) for j in y_test for i in j]\n",
    "            y_pred_exp = [int(i) for j in y_pred for i in j]\n",
    "       \n",
    "\n",
    "            f1_out = f1_score (y_true = y_test_exp, y_pred = y_pred_exp)\n",
    "            recall_out = recall_score(y_true = y_test_exp, y_pred = y_pred_exp)\n",
    "            prec_out = precision_score (y_true = y_test_exp, y_pred = y_pred_exp)\n",
    "\n",
    "            out['F1'].append(f1_out)\n",
    "            out['recall'].append(recall_out)\n",
    "            out['precision'].append(prec_out)\n",
    " \n",
    "            out['best_param'].append(rs.best_params_)\n",
    "  \n",
    "        print('The mean F1 score for BERT + CRF is: ')\n",
    "        avg = np.mean(out['F1']) \n",
    "        self.currentf1 = avg\n",
    "        print(str(avg))  \n",
    "        \n",
    "        self.crf_params = out['best_param']\n",
    "        \n",
    "        return out\n",
    "       \n",
    "    \n",
    "    def run_crf_preset_blended_doublerun(self, data, prevaddlst, addlst, predlbls, crf_params, basepath_probas):  \n",
    "        out = defaultdict(list)\n",
    "\n",
    "        f1_scorer = make_scorer(metrics.flat_fbeta_score, beta=1,\n",
    "                            average='weighted', labels=[0,1])\n",
    "\n",
    "        for p, d, l in zip(crf_params, self.folddicts, ['fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9', 'fold10']):\n",
    "\n",
    "            p1 = p['c1']\n",
    "            p2 = p['c2']\n",
    "\n",
    "            crf = sklearn_crfsuite.CRF(\n",
    "                algorithm='lbfgs',\n",
    "                c1 =p1, \n",
    "                c2 = p2,\n",
    "                max_iterations=100,\n",
    "                all_possible_transitions=True\n",
    "            )\n",
    "\n",
    "\n",
    "            train_df, test_df, trainlbls, testlbls, train_q, test_q = self.obtain_probas_nw(data, d, l, basepath_probas)\n",
    "\n",
    "            xtra_train_df, xtra_test_df = self.obtain_other_features(data, d)  \n",
    "\n",
    "            labeldistlst = ['prev_post_label', 'RuncountNeg', 'RuncountPos', 'DistanceLbl0', 'DistanceLbl1', 'RelRuncount']\n",
    "            prevaddlst2 = [i for i in prevaddlst if i not in labeldistlst]\n",
    "\n",
    "            if addlst in labeldistlst: \n",
    "                addlst2 = []\n",
    "            else: \n",
    "                addlst2 = addlst\n",
    "\n",
    "            combolst = []\n",
    "            [combolst.append(i) for i in prevaddlst]\n",
    "            combolst.append(addlst)\n",
    "\n",
    "\n",
    "            set1= set(combolst)\n",
    "            set2 = set(labeldistlst)\n",
    "\n",
    "            droplst = [i for i in labeldistlst if i not in combolst]\n",
    "\n",
    "            X_train1 = train_df\n",
    "            for i in prevaddlst2: \n",
    "                X_train1 = pd.concat([X_train1, xtra_train_df[i]], axis=1)\n",
    "\n",
    "            if addlst2  != []: \n",
    "                X_train1 = pd.concat([X_train1, xtra_train_df[addlst]], axis=1)\n",
    "\n",
    "            ##now add all the label dist \n",
    "            for i in labeldistlst: \n",
    "                X_train1 = pd.concat([X_train1, xtra_train_df[i]], axis=1)\n",
    "\n",
    "            ##now drop the unnecessary ones\n",
    "            X_train1 = X_train1.drop (labels = droplst, axis=1)\n",
    "\n",
    "\n",
    "            startp = self.get_thread_startpoints(train_q)\n",
    "            y_train = self.reformat_labels_blend(trainlbls, startp)\n",
    "\n",
    "            #reformat X_train\n",
    "            X_train_nw = self.reformat_for_crf(X_train1, startp)    \n",
    "\n",
    "            crf.fit(X_train_nw, y_train)\n",
    "\n",
    "            ##testing phase\n",
    "            X_test2 = test_df\n",
    "\n",
    "            for i in prevaddlst2: \n",
    "                X_test2 = pd.concat([X_test2, xtra_test_df[i]], axis=1)\n",
    "    #             print(X_test2.columns)\n",
    "\n",
    "            if addlst2  != []: \n",
    "                X_test2 = pd.concat([X_test2, xtra_test_df[addlst]], axis=1)\n",
    "\n",
    "\n",
    "            startp = self.get_thread_startpoints(test_q)\n",
    "            y_test = self.reformat_labels_blend(testlbls, startp)\n",
    "\n",
    "\n",
    "            ##first run \n",
    "\n",
    "            X_test_nw = self.reformat_for_crf(X_test2, startp)\n",
    "\n",
    "\n",
    "            ## make dummy versions of all necessary\n",
    "\n",
    "            if len(set1.intersection(set2)) > 0 : \n",
    "                X_test_nwer = []\n",
    "                for t in X_test_nw: \n",
    "                    temp = [] ##temporary thread\n",
    "                    for num, p in enumerate(t): ##p is a dictionary for the post\n",
    "                        nwp = p\n",
    "                        if 'prev_post_label' in combolst: \n",
    "                            nwp['prev_post_label'] = 0 \n",
    "                        if 'RuncountNeg' in combolst:\n",
    "                            nwp['RuncountNeg'] = num\n",
    "                        if 'RuncountPos' in combolst:\n",
    "                            nwp['RuncountPos'] = 0\n",
    "\n",
    "                        if 'DistanceLbl0' in combolst:\n",
    "                            nwp['DistanceLbl0'] = 0\n",
    "                        if 'DistLbl1' in combolst:\n",
    "                            nwp['DistLbl1'] = 999 ##same as infinite - there have been none\n",
    "                        if 'RelRuncount' in combolst:\n",
    "                            nwp['RelRuncount'] = 0\n",
    "\n",
    "                        temp.append(nwp)\n",
    "                    X_test_nwer.append(temp)\n",
    "            else: \n",
    "                X_test_nwer = X_test_nw\n",
    "\n",
    "            ##first prediction round (or last if no label dist values.)\n",
    "            y_pred_first = crf.predict(X_test_nwer)\n",
    "\n",
    "           ##second prediction if necessary \n",
    "\n",
    "            if len(set1.intersection(set2)) > 0 : \n",
    "                X_test_nwest = [] ## for all threads\n",
    "                for a,b in zip(X_test_nwer, y_pred_first): ##these are threads\n",
    "                    ##initialize\n",
    "\n",
    "                    temp = [] ##for one thread\n",
    "\n",
    "                    ds = 0\n",
    "                    c0 = 0\n",
    "                    c1 = 0\n",
    "                    d0 = 999\n",
    "                    d1 = 999\n",
    "                    rel_c = 0\n",
    "                    for p, l in zip (a,b): #these are the individual posts - l is predlbl\n",
    "                        nwp = p\n",
    "                        ##update dictionary\n",
    "                        if 'prev_post_label' in combolst: \n",
    "                            nwp['prev_post_label'] = l\n",
    "                        if 'RuncountNeg' in combolst:\n",
    "                            nwp['RuncountNeg'] = c0\n",
    "                        if 'RuncountPos' in combolst:\n",
    "                            nwp['RuncountPos'] = c1\n",
    "\n",
    "                        if 'DistanceLbl0' in combolst:\n",
    "                            nwp['DistanceLbl0'] = d0\n",
    "                        if 'DistLbl1' in combolst:\n",
    "                            nwp['DistLbl1'] = d1 ##same as infinite - there have been none\n",
    "                        if 'RelRuncount' in combolst:\n",
    "                            nwp['RelRuncount'] = rel_c\n",
    "\n",
    "                        temp.append(nwp)\n",
    "\n",
    "                        ##update values for next one\n",
    "                        prevlbl = l\n",
    "                        if prevlbl == 0: \n",
    "                            c0 += 1\n",
    "                            d0 = 0\n",
    "                            if d1 == 999: \n",
    "                                d1 = 999\n",
    "                            else: \n",
    "                                d1 +=1\n",
    "                        elif prevlbl ==1: \n",
    "                            c1 += 1\n",
    "                            d1 = 0\n",
    "                            if d0 == 999: \n",
    "                                d0 = 999\n",
    "                            else: \n",
    "                                d0 += 1\n",
    "                        ds = ds +1\n",
    "\n",
    "                        if c1 == 0: \n",
    "                            rel_c= 0\n",
    "                        else:\n",
    "                            rel_c = (c1/ds)\n",
    "                    ##thread is done - add to new Xtest\n",
    "                    X_test_nwest.append(temp)\n",
    "\n",
    "\n",
    "\n",
    "                y_pred_nw = crf.predict(X_test_nwest)\n",
    "                y_pred_exp = [int(i) for j in y_pred_nw for i in j]\n",
    "\n",
    "            else: \n",
    "                y_pred_exp = [int(i) for j in y_pred_first for i in j]\n",
    "\n",
    "\n",
    "            y_test_exp= [int(i) for j in y_test for i in j]\n",
    "\n",
    "            f1_out = f1_score (y_true = y_test_exp, y_pred = y_pred_exp)         \n",
    "            recall_out = recall_score(y_true = y_test_exp, y_pred = y_pred_exp)\n",
    "            prec_out = precision_score (y_true = y_test_exp, y_pred = y_pred_exp)\n",
    "    #         auc_out = roc_auc_score(y_true = y_test, y_pred= y_pred)\n",
    "            out['F1'].append(f1_out)\n",
    "            out['recall'].append(recall_out)\n",
    "            out['precision'].append(prec_out)\n",
    "        \n",
    "        avg = np.mean(out['F1'])\n",
    "        \n",
    "        return out, avg\n",
    "    \n",
    "    def forward_feature_selection(self, data,  basepath_probas, outpath, currentf1, da_acts = False): \n",
    "        \n",
    "        if da_acts == True: \n",
    "            origfeaturelst = ['prev_post_label', 'distance_score', 'prev_sim', 'RuncountNeg', 'RuncountPos', 'RelRuncount', 'DistanceLbl0', 'DistanceLbl1', 'thread_sim', 'da_acts', 'da_acts_prev']\n",
    "        else: \n",
    "             origfeaturelst = ['prev_post_label', 'distance_score', 'prev_sim', 'RuncountNeg', 'RuncountPos', 'RelRuncount', 'DistanceLbl0', 'DistanceLbl1', 'thread_sim']\n",
    "\n",
    "        featurelst = origfeaturelst\n",
    "        prevaddlst = []\n",
    "        current_F1 = currentf1\n",
    "        improv_f1 = []\n",
    "        improv_f1.append(currentf1)\n",
    "        quit = 0\n",
    "        round_num =1\n",
    "\n",
    "        while quit == 0 : \n",
    "            round_dict = {}\n",
    "            res = []\n",
    "            for j in featurelst: \n",
    "                ##run CRF experiments\n",
    "#                 print(j)\n",
    "                if j == 'prev_post_label' or 'prev_post_label' in prevaddlst:\n",
    "                    p = True\n",
    "                else: \n",
    "                    p = False\n",
    "\n",
    "                out, avg = self.run_crf_preset_blended_doublerun(data,prevaddlst, addlst=j, predlbls = p, crf_params=self.crf_params, basepath_probas = basepath_probas)            \n",
    "                round_dict[j] = out\n",
    "\n",
    "                res.append(avg)\n",
    "            ##save rounddict\n",
    "            savepath = outpath + 'round_dict' + str(round_num)\n",
    "            self.save_obj(round_dict, savepath)\n",
    "\n",
    "            ##get the best\n",
    "            bestix = res.index(np.max(res))\n",
    "            bestval = np.max(res)\n",
    "            if bestval > current_F1: \n",
    "                pass\n",
    "            else: \n",
    "#                 print('Time to quit')\n",
    "                quit = 1 ##quit if the best feature adds nothing.\n",
    "\n",
    "#             print('And the best feature is ... ')\n",
    "            bestfeat = featurelst[bestix]   \n",
    "#             print(bestfeat)\n",
    "\n",
    "            round_num = round_num + 1\n",
    "\n",
    "            ##update feature list\n",
    "            prevaddlst.append(bestfeat)\n",
    "            featurelst = [i for i in featurelst if i != bestfeat] ##remove the feature from the list\n",
    "            current_F1 = bestval\n",
    "            improv_f1.append(bestval)\n",
    "            self.save_obj(prevaddlst, outpath + 'features_added')\n",
    "            self.save_obj(current_F1, outpath + 'best_f1')\n",
    "            self.save_obj(improv_f1, outpath + 'steps_f1')\n",
    "        \n",
    "            ##return some outcome to print\n",
    "        print('The new best F1 score is: ')\n",
    "        print(current_F1)\n",
    "        \n",
    "        print('The added features to attain this were: ')\n",
    "        print(prevaddlst)\n",
    "        \n",
    "#         return prevaddlst, current_F1\n",
    "        \n",
    "    def main(self, data, outpath, da_acts = False): \n",
    "        self.make_dir(outpath)\n",
    "        self.create_fold_dict(data, outpath)\n",
    "        self.run_BERT(data, outpath)\n",
    "        self.calculate_BERT_metrics(data, outpath)\n",
    "    \n",
    "        basepath_probas = outpath + 'BERTprobs/'\n",
    "        \n",
    "        outblend = self.run_BlendedBERTCRF( data, basepath_probas)\n",
    "\n",
    "        self.save_obj(outblend, outpath + 'BlendedBERTresults')\n",
    "        \n",
    "        nwoutpath = outpath + '/FeatureSelect/'\n",
    "        \n",
    "        self.forward_feature_selection(data, basepath_probas, nwoutpath, currentf1 = self.currentf1, da_acts = False)\n",
    "        \n",
    "#         self.save_obj(outfeat, outpath + 'FeatureSelectionresults')\n",
    "        \n",
    "#         return outblend, outfeat\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "205\n",
      "205\n",
      "435\n",
      "435\n",
      "88\n",
      "88\n",
      "79\n",
      "79\n",
      "158\n",
      "158\n",
      "116\n",
      "116\n",
      "105\n",
      "105\n",
      "214\n",
      "214\n",
      "85\n",
      "85\n",
      "71\n",
      "71\n",
      "The F1 score for BERT is: \n",
      "0.38905047746292853\n"
     ]
    }
   ],
   "source": [
    "##load data \n",
    "data = pd.read_csv('/data/dirksonar/Temp/ExampleDatawithFeat.tsv', sep = '\\t')\n",
    "# print(data.head())\n",
    "\n",
    "outpath = '/data/dirksonar/Temp/'\n",
    "\n",
    "ConvAwareModel().main(data, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
