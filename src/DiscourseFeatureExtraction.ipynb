{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(): \n",
    "    \n",
    "    def __init__(self): \n",
    "        self.embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "    def get_running_count_binary(self, data, threadheader): \n",
    "        runcountpos = []\n",
    "        runcountneg = []\n",
    "        distlabel0 = []\n",
    "        distlabel1 = []\n",
    "        c0 = 0\n",
    "        c1 = 0\n",
    "        d1 = 999\n",
    "        d2 = 999\n",
    "        prev_thread = 0\n",
    "        for a,b in zip(data[threadheader], data['label']): \n",
    "            if a == prev_thread: ##still same question\n",
    "\n",
    "                distlabel0.append(d0)\n",
    "                distlabel1.append(d1)\n",
    "\n",
    "                if b == 0: \n",
    "                    c0 += 1\n",
    "                    d0 = 0\n",
    "                    if d1 == 999: \n",
    "                        d1 = 999\n",
    "                    else: \n",
    "                        d1 +=1\n",
    "                elif b ==1: \n",
    "                    c1 += 1\n",
    "                    d1 = 0\n",
    "                    if d0 == 999: \n",
    "                        d0 = 999\n",
    "                    else: \n",
    "                        d0 += 1\n",
    "                else: \n",
    "                    print(\"Labels are different\")\n",
    "                runcountneg.append(c0) \n",
    "                runcountpos.append(c1)\n",
    "\n",
    "\n",
    "            else: \n",
    "                prev_thread = a\n",
    "                c0 =0\n",
    "                c1= 0 \n",
    "                d1 = 999\n",
    "                d0 = 999\n",
    "                runcountneg.append(c0)\n",
    "                runcountpos.append(c1)\n",
    "                distlabel0.append(d0)\n",
    "                distlabel1.append(d1)\n",
    "\n",
    "                if b == 0: \n",
    "                    d0 = 0 \n",
    "                    d1= 999\n",
    "                if b == 1: \n",
    "                    d1 = 1\n",
    "                    d0 = 999\n",
    "\n",
    "        return runcountneg, runcountpos, distlabel0, distlabel1\n",
    "\n",
    "    def set_seed(self,num):\n",
    "    #     random.seed(num)\n",
    "        np.random.seed(num)\n",
    "    #     torch.manual_seed(num)\n",
    "    #     if n_gpu > 0:\n",
    "    #             torch.cuda.manual_seed_all(num)\n",
    "\n",
    "    def cosine_similarity(self,v1, v2):\n",
    "        mag1 = np.linalg.norm(v1)\n",
    "        mag2 = np.linalg.norm(v2)\n",
    "        if (not mag1) or (not mag2):\n",
    "            return 0\n",
    "        return np.dot(v1, v2) / (mag1 * mag2)\n",
    "\n",
    "    def test_similarity(self,text1, text2):\n",
    "        vecs = self.embed([text1, text2])\n",
    "        v1 = vecs[0]\n",
    "        v2 = vecs[1]\n",
    "        return self.cosine_similarity(v1, v2)\n",
    "\n",
    "    def sent_vec(self,text1):\n",
    "        vec = self.embed(text1) ['outputs']\n",
    "        return vec\n",
    "    \n",
    "    def calculate_thread_sim(self, data, threadheader): ##compared to the other messages in the thread\n",
    "        thread_sim = []\n",
    "        for a,b,c in zip(data.comment_text, data[threadheader], data.post_id): \n",
    "            df= data[data[threadheader] == b]\n",
    "            df2 = df[df.post_id != c]\n",
    "            threadtxt = \" \".join(df2.comment_text)\n",
    "\n",
    "            t = self.test_similarity(a, threadtxt)\n",
    "\n",
    "            thread_sim.append(t)\n",
    "        return thread_sim\n",
    "    \n",
    "    def get_rel_running_count(self,data): \n",
    "        all_rel_c = []\n",
    "        for a,b in zip(data.RuncountPos, data.distance_score): \n",
    "            if a == 999: \n",
    "                rel_c = 0\n",
    "            else: \n",
    "                rel_c = (a/b)*100\n",
    "            all_rel_c.append(rel_c)\n",
    "        return all_rel_c\n",
    "    \n",
    "    def prev_similarity (self, row): \n",
    "        t1 = row.comment_text\n",
    "        t2 = row.prev_post_text\n",
    "        if t2 != None: \n",
    "            return self.test_similarity(t1, t2)\n",
    "        else: \n",
    "            return None\n",
    "        \n",
    "        \n",
    "    def distance_score (self, data): \n",
    "        lst1 = list(data.thread_id) \n",
    "        lst2 = []\n",
    "\n",
    "        c= 1 \n",
    "        current_q = 0\n",
    "        # print(current_q)\n",
    "\n",
    "        for i in lst1: \n",
    "            if i != current_q: \n",
    "                c =1 \n",
    "                current_q = i\n",
    "                lst2.append(c)\n",
    "            else: \n",
    "                c = c+1 \n",
    "                lst2.append(c)\n",
    "        return lst2        \n",
    "        \n",
    "    def get_prev_post_id (self, lst1, lst3): \n",
    "        #end posts\n",
    "        lst2= []\n",
    "        for num,i in enumerate(lst1): \n",
    "            if num == 0: \n",
    "                lst2.append(None)\n",
    "    #             pass\n",
    "            elif lst3[num] == lst3[num-1]: ##same question \n",
    "                lst2.append(lst1[num-1])\n",
    "            else: ##different question\n",
    "                lst2.append(None)\n",
    "        return lst2\n",
    "    \n",
    "    def get_prev_post_text (self, row): \n",
    "        ix = row.prev_post_id\n",
    "        if ix != None: \n",
    "            txt = self.d[ix]\n",
    "\n",
    "            return txt\n",
    "        else: \n",
    "            return None\n",
    "        \n",
    "    def create_dict_text(self,data):\n",
    "        self.d= {}\n",
    "        for a,b in zip(data.comment_text, data.post_id): \n",
    "            self.d[b] = a\n",
    "            \n",
    "    def create_dict_labels(self,data):\n",
    "        self.d2= {}\n",
    "        for a,b in zip(data.label, data.post_id): \n",
    "            self.d2[b] = a\n",
    "        \n",
    "            \n",
    "    def get_label_prev (self,row):\n",
    "        ix = row.prev_post_id\n",
    "        if ix != None:\n",
    "            ac = self.d2[ix]\n",
    "            return ac\n",
    "        else: \n",
    "            return None\n",
    "        \n",
    "\n",
    "    \n",
    "    def main (self,datapath, outpath): \n",
    "        self.set_seed(1)\n",
    "        \n",
    "        data = pd.read_csv(datapath, sep= '\\t')\n",
    "        self.create_dict_text(data)\n",
    "        self.create_dict_labels(data)\n",
    "        \n",
    "        ##get the ids of hte previous posts\n",
    "        lst2 = self.get_prev_post_id(data.post_id, data.thread_id)\n",
    "        \n",
    "        data2 = pd.concat([data, pd.Series(lst2, name = \"prev_post_id\")], axis=1)\n",
    "        \n",
    "        ##get text and label of previous post\n",
    "\n",
    "        data2['prev_post_label'] = data2.apply(lambda x: self.get_label_prev(x), axis=1)    \n",
    "        \n",
    "        data2['prev_post_text'] = data2.apply(lambda x: self.get_prev_post_text (x), axis=1)\n",
    "        \n",
    "        ##calculate similarity to previous post and thread \n",
    "        data2['prev_sim']= data2.apply(lambda x: self.prev_similarity(x), axis =1)\n",
    "        \n",
    "        data2 = data2.reset_index(drop= True)\n",
    "        \n",
    "        thread_sim = self.calculate_thread_sim(data2, threadheader = 'thread_id')\n",
    "        \n",
    "        ##calculate distance score \n",
    "        dist = self.distance_score(data)\n",
    "        \n",
    "        ##calculate label distribution features\n",
    "                \n",
    "        runcountneg, runcountpos, distlabel0, distlabel1 = self.get_running_count_binary(data2, 'thread_id')\n",
    "        \n",
    "        data3 = pd.concat([data2, pd.Series(dist, name= 'distance_score'), pd.Series(thread_sim, name = 'thread_sim'), pd.Series(runcountneg, name ='RuncountNeg'), pd.Series(runcountpos, name ='RuncountPos'), pd.Series(distlabel0, name ='DistanceLbl0'), pd.Series(runcountneg, name ='DistanceLbl1')], axis=1)\n",
    "        \n",
    "        rel_c = self.get_rel_running_count(data3)\n",
    "        \n",
    "        feat_df = pd.concat([data3, pd.Series(rel_c, name = 'RelRuncount')], axis=1)\n",
    "        \n",
    "        feat_df.to_csv(outpath, sep = '\\t', index = False)\n",
    "        return feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'C:/Users/dirksonar/Documents/Data/Project8_Discourse/Misinfo/ExampleData.tsv'\n",
    "outpath = 'C:/Users/dirksonar/Documents/Data/Project8_Discourse/Misinfo/ExampleDatawithFeat.tsv'\n",
    "out= FeatureExtractor().main(datapath, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
